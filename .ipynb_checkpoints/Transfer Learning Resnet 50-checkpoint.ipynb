{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transfer Learning VGG 16 and VGG 19 using Keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Please download the dataset from the below url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the libraries as shown below\n",
    "\n",
    "from tensorflow.keras.layers import Input, Lambda, Dense, Flatten\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.applications.resnet50 import ResNet50\n",
    "#from keras.applications.vgg16 import VGG16\n",
    "from tensorflow.keras.applications.resnet50 import preprocess_input\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator,load_img\n",
    "from tensorflow.keras.models import Sequential\n",
    "import numpy as np\n",
    "from glob import glob\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: keras\n",
      "Version: 2.9.0\n",
      "Summary: Deep learning for humans.\n",
      "Home-page: https://keras.io/\n",
      "Author: Keras team\n",
      "Author-email: keras-users@googlegroups.com\n",
      "License: Apache 2.0\n",
      "Location: c:\\users\\parag kapoor\\anaconda3\\lib\\site-packages\n",
      "Requires: \n",
      "Required-by: tensorflow\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip show keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# re-size all the images to this\n",
    "IMAGE_SIZE = [224, 224]\n",
    "\n",
    "train_path = 'Datasets/train'\n",
    "valid_path = 'Datasets/test'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A local file was found, but it seems to be incomplete or outdated because the auto file hash does not match the original value of 4d473c1dd8becc155b73f8504c6f6626 so we will re-download the data.\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "94765736/94765736 [==============================] - 9s 0us/step\n"
     ]
    }
   ],
   "source": [
    "# Import the Vgg 16 library as shown below and add preprocessing layer to the front of VGG\n",
    "# Here we will be using imagenet weights\n",
    "\n",
    "resnet = ResNet50(input_shape=IMAGE_SIZE + [3], weights='imagenet', include_top=False)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# don't train existing weights\n",
    "for layer in resnet.layers:\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "  # useful for getting number of output classes\n",
    "folders = glob('Datasets/train/*')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# our layers - you can add more if you want\n",
    "x = Flatten()(resnet.output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = Dense(len(folders), activation='softmax')(x)\n",
    "\n",
    "# create a model object\n",
    "model = Model(inputs=resnet.input, outputs=prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_3 (InputLayer)            (None, 224, 224, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1_pad (ZeroPadding2D)       (None, 230, 230, 3)  0           input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1 (Conv2D)                  (None, 112, 112, 64) 9472        conv1_pad[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "bn_conv1 (BatchNormalizationV1) (None, 112, 112, 64) 256         conv1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_98 (Activation)      (None, 112, 112, 64) 0           bn_conv1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "pool1_pad (ZeroPadding2D)       (None, 114, 114, 64) 0           activation_98[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2D)  (None, 56, 56, 64)   0           pool1_pad[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "res2a_branch2a (Conv2D)         (None, 56, 56, 64)   4160        max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "bn2a_branch2a (BatchNormalizati (None, 56, 56, 64)   256         res2a_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_99 (Activation)      (None, 56, 56, 64)   0           bn2a_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2a_branch2b (Conv2D)         (None, 56, 56, 64)   36928       activation_99[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn2a_branch2b (BatchNormalizati (None, 56, 56, 64)   256         res2a_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_100 (Activation)     (None, 56, 56, 64)   0           bn2a_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2a_branch2c (Conv2D)         (None, 56, 56, 256)  16640       activation_100[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "res2a_branch1 (Conv2D)          (None, 56, 56, 256)  16640       max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "bn2a_branch2c (BatchNormalizati (None, 56, 56, 256)  1024        res2a_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn2a_branch1 (BatchNormalizatio (None, 56, 56, 256)  1024        res2a_branch1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_32 (Add)                    (None, 56, 56, 256)  0           bn2a_branch2c[0][0]              \n",
      "                                                                 bn2a_branch1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_101 (Activation)     (None, 56, 56, 256)  0           add_32[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res2b_branch2a (Conv2D)         (None, 56, 56, 64)   16448       activation_101[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn2b_branch2a (BatchNormalizati (None, 56, 56, 64)   256         res2b_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_102 (Activation)     (None, 56, 56, 64)   0           bn2b_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2b_branch2b (Conv2D)         (None, 56, 56, 64)   36928       activation_102[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn2b_branch2b (BatchNormalizati (None, 56, 56, 64)   256         res2b_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_103 (Activation)     (None, 56, 56, 64)   0           bn2b_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2b_branch2c (Conv2D)         (None, 56, 56, 256)  16640       activation_103[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn2b_branch2c (BatchNormalizati (None, 56, 56, 256)  1024        res2b_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_33 (Add)                    (None, 56, 56, 256)  0           bn2b_branch2c[0][0]              \n",
      "                                                                 activation_101[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_104 (Activation)     (None, 56, 56, 256)  0           add_33[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res2c_branch2a (Conv2D)         (None, 56, 56, 64)   16448       activation_104[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn2c_branch2a (BatchNormalizati (None, 56, 56, 64)   256         res2c_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_105 (Activation)     (None, 56, 56, 64)   0           bn2c_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2c_branch2b (Conv2D)         (None, 56, 56, 64)   36928       activation_105[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn2c_branch2b (BatchNormalizati (None, 56, 56, 64)   256         res2c_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_106 (Activation)     (None, 56, 56, 64)   0           bn2c_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2c_branch2c (Conv2D)         (None, 56, 56, 256)  16640       activation_106[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn2c_branch2c (BatchNormalizati (None, 56, 56, 256)  1024        res2c_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_34 (Add)                    (None, 56, 56, 256)  0           bn2c_branch2c[0][0]              \n",
      "                                                                 activation_104[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_107 (Activation)     (None, 56, 56, 256)  0           add_34[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res3a_branch2a (Conv2D)         (None, 28, 28, 128)  32896       activation_107[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn3a_branch2a (BatchNormalizati (None, 28, 28, 128)  512         res3a_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_108 (Activation)     (None, 28, 28, 128)  0           bn3a_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3a_branch2b (Conv2D)         (None, 28, 28, 128)  147584      activation_108[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn3a_branch2b (BatchNormalizati (None, 28, 28, 128)  512         res3a_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_109 (Activation)     (None, 28, 28, 128)  0           bn3a_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3a_branch2c (Conv2D)         (None, 28, 28, 512)  66048       activation_109[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "res3a_branch1 (Conv2D)          (None, 28, 28, 512)  131584      activation_107[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn3a_branch2c (BatchNormalizati (None, 28, 28, 512)  2048        res3a_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn3a_branch1 (BatchNormalizatio (None, 28, 28, 512)  2048        res3a_branch1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_35 (Add)                    (None, 28, 28, 512)  0           bn3a_branch2c[0][0]              \n",
      "                                                                 bn3a_branch1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_110 (Activation)     (None, 28, 28, 512)  0           add_35[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res3b_branch2a (Conv2D)         (None, 28, 28, 128)  65664       activation_110[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn3b_branch2a (BatchNormalizati (None, 28, 28, 128)  512         res3b_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_111 (Activation)     (None, 28, 28, 128)  0           bn3b_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3b_branch2b (Conv2D)         (None, 28, 28, 128)  147584      activation_111[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn3b_branch2b (BatchNormalizati (None, 28, 28, 128)  512         res3b_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_112 (Activation)     (None, 28, 28, 128)  0           bn3b_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3b_branch2c (Conv2D)         (None, 28, 28, 512)  66048       activation_112[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn3b_branch2c (BatchNormalizati (None, 28, 28, 512)  2048        res3b_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_36 (Add)                    (None, 28, 28, 512)  0           bn3b_branch2c[0][0]              \n",
      "                                                                 activation_110[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_113 (Activation)     (None, 28, 28, 512)  0           add_36[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res3c_branch2a (Conv2D)         (None, 28, 28, 128)  65664       activation_113[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn3c_branch2a (BatchNormalizati (None, 28, 28, 128)  512         res3c_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_114 (Activation)     (None, 28, 28, 128)  0           bn3c_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3c_branch2b (Conv2D)         (None, 28, 28, 128)  147584      activation_114[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn3c_branch2b (BatchNormalizati (None, 28, 28, 128)  512         res3c_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_115 (Activation)     (None, 28, 28, 128)  0           bn3c_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3c_branch2c (Conv2D)         (None, 28, 28, 512)  66048       activation_115[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn3c_branch2c (BatchNormalizati (None, 28, 28, 512)  2048        res3c_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_37 (Add)                    (None, 28, 28, 512)  0           bn3c_branch2c[0][0]              \n",
      "                                                                 activation_113[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_116 (Activation)     (None, 28, 28, 512)  0           add_37[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res3d_branch2a (Conv2D)         (None, 28, 28, 128)  65664       activation_116[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn3d_branch2a (BatchNormalizati (None, 28, 28, 128)  512         res3d_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_117 (Activation)     (None, 28, 28, 128)  0           bn3d_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3d_branch2b (Conv2D)         (None, 28, 28, 128)  147584      activation_117[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn3d_branch2b (BatchNormalizati (None, 28, 28, 128)  512         res3d_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_118 (Activation)     (None, 28, 28, 128)  0           bn3d_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3d_branch2c (Conv2D)         (None, 28, 28, 512)  66048       activation_118[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn3d_branch2c (BatchNormalizati (None, 28, 28, 512)  2048        res3d_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_38 (Add)                    (None, 28, 28, 512)  0           bn3d_branch2c[0][0]              \n",
      "                                                                 activation_116[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_119 (Activation)     (None, 28, 28, 512)  0           add_38[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res4a_branch2a (Conv2D)         (None, 14, 14, 256)  131328      activation_119[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn4a_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4a_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_120 (Activation)     (None, 14, 14, 256)  0           bn4a_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4a_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_120[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn4a_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4a_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_121 (Activation)     (None, 14, 14, 256)  0           bn4a_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4a_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_121[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "res4a_branch1 (Conv2D)          (None, 14, 14, 1024) 525312      activation_119[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn4a_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4a_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn4a_branch1 (BatchNormalizatio (None, 14, 14, 1024) 4096        res4a_branch1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_39 (Add)                    (None, 14, 14, 1024) 0           bn4a_branch2c[0][0]              \n",
      "                                                                 bn4a_branch1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_122 (Activation)     (None, 14, 14, 1024) 0           add_39[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res4b_branch2a (Conv2D)         (None, 14, 14, 256)  262400      activation_122[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn4b_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4b_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_123 (Activation)     (None, 14, 14, 256)  0           bn4b_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4b_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_123[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn4b_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4b_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_124 (Activation)     (None, 14, 14, 256)  0           bn4b_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4b_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_124[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn4b_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4b_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_40 (Add)                    (None, 14, 14, 1024) 0           bn4b_branch2c[0][0]              \n",
      "                                                                 activation_122[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_125 (Activation)     (None, 14, 14, 1024) 0           add_40[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res4c_branch2a (Conv2D)         (None, 14, 14, 256)  262400      activation_125[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn4c_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4c_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_126 (Activation)     (None, 14, 14, 256)  0           bn4c_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4c_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_126[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn4c_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4c_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_127 (Activation)     (None, 14, 14, 256)  0           bn4c_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4c_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_127[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn4c_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4c_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_41 (Add)                    (None, 14, 14, 1024) 0           bn4c_branch2c[0][0]              \n",
      "                                                                 activation_125[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_128 (Activation)     (None, 14, 14, 1024) 0           add_41[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res4d_branch2a (Conv2D)         (None, 14, 14, 256)  262400      activation_128[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn4d_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4d_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_129 (Activation)     (None, 14, 14, 256)  0           bn4d_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4d_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_129[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn4d_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4d_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_130 (Activation)     (None, 14, 14, 256)  0           bn4d_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4d_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_130[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn4d_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4d_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_42 (Add)                    (None, 14, 14, 1024) 0           bn4d_branch2c[0][0]              \n",
      "                                                                 activation_128[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_131 (Activation)     (None, 14, 14, 1024) 0           add_42[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res4e_branch2a (Conv2D)         (None, 14, 14, 256)  262400      activation_131[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn4e_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4e_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_132 (Activation)     (None, 14, 14, 256)  0           bn4e_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4e_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_132[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn4e_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4e_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_133 (Activation)     (None, 14, 14, 256)  0           bn4e_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4e_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_133[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn4e_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4e_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_43 (Add)                    (None, 14, 14, 1024) 0           bn4e_branch2c[0][0]              \n",
      "                                                                 activation_131[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_134 (Activation)     (None, 14, 14, 1024) 0           add_43[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res4f_branch2a (Conv2D)         (None, 14, 14, 256)  262400      activation_134[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn4f_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4f_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_135 (Activation)     (None, 14, 14, 256)  0           bn4f_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4f_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_135[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn4f_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4f_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_136 (Activation)     (None, 14, 14, 256)  0           bn4f_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4f_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_136[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn4f_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4f_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_44 (Add)                    (None, 14, 14, 1024) 0           bn4f_branch2c[0][0]              \n",
      "                                                                 activation_134[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_137 (Activation)     (None, 14, 14, 1024) 0           add_44[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res5a_branch2a (Conv2D)         (None, 7, 7, 512)    524800      activation_137[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn5a_branch2a (BatchNormalizati (None, 7, 7, 512)    2048        res5a_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_138 (Activation)     (None, 7, 7, 512)    0           bn5a_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5a_branch2b (Conv2D)         (None, 7, 7, 512)    2359808     activation_138[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn5a_branch2b (BatchNormalizati (None, 7, 7, 512)    2048        res5a_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_139 (Activation)     (None, 7, 7, 512)    0           bn5a_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5a_branch2c (Conv2D)         (None, 7, 7, 2048)   1050624     activation_139[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "res5a_branch1 (Conv2D)          (None, 7, 7, 2048)   2099200     activation_137[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn5a_branch2c (BatchNormalizati (None, 7, 7, 2048)   8192        res5a_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn5a_branch1 (BatchNormalizatio (None, 7, 7, 2048)   8192        res5a_branch1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_45 (Add)                    (None, 7, 7, 2048)   0           bn5a_branch2c[0][0]              \n",
      "                                                                 bn5a_branch1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_140 (Activation)     (None, 7, 7, 2048)   0           add_45[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res5b_branch2a (Conv2D)         (None, 7, 7, 512)    1049088     activation_140[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn5b_branch2a (BatchNormalizati (None, 7, 7, 512)    2048        res5b_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_141 (Activation)     (None, 7, 7, 512)    0           bn5b_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5b_branch2b (Conv2D)         (None, 7, 7, 512)    2359808     activation_141[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn5b_branch2b (BatchNormalizati (None, 7, 7, 512)    2048        res5b_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_142 (Activation)     (None, 7, 7, 512)    0           bn5b_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5b_branch2c (Conv2D)         (None, 7, 7, 2048)   1050624     activation_142[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn5b_branch2c (BatchNormalizati (None, 7, 7, 2048)   8192        res5b_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_46 (Add)                    (None, 7, 7, 2048)   0           bn5b_branch2c[0][0]              \n",
      "                                                                 activation_140[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_143 (Activation)     (None, 7, 7, 2048)   0           add_46[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res5c_branch2a (Conv2D)         (None, 7, 7, 512)    1049088     activation_143[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn5c_branch2a (BatchNormalizati (None, 7, 7, 512)    2048        res5c_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_144 (Activation)     (None, 7, 7, 512)    0           bn5c_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5c_branch2b (Conv2D)         (None, 7, 7, 512)    2359808     activation_144[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn5c_branch2b (BatchNormalizati (None, 7, 7, 512)    2048        res5c_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_145 (Activation)     (None, 7, 7, 512)    0           bn5c_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5c_branch2c (Conv2D)         (None, 7, 7, 2048)   1050624     activation_145[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn5c_branch2c (BatchNormalizati (None, 7, 7, 2048)   8192        res5c_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_47 (Add)                    (None, 7, 7, 2048)   0           bn5c_branch2c[0][0]              \n",
      "                                                                 activation_143[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_146 (Activation)     (None, 7, 7, 2048)   0           add_47[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "flatten_2 (Flatten)             (None, 100352)       0           activation_146[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 3)            301059      flatten_2[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 23,888,771\n",
      "Trainable params: 301,059\n",
      "Non-trainable params: 23,587,712\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# view the structure of the model\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tell the model what cost and optimization method to use\n",
    "model.compile(\n",
    "  loss='categorical_crossentropy',\n",
    "  optimizer='adam',\n",
    "  metrics=['accuracy']\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the Image Data Generator to import the images from the dataset\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "train_datagen = ImageDataGenerator(rescale = 1./255,\n",
    "                                   shear_range = 0.2,\n",
    "                                   zoom_range = 0.2,\n",
    "                                   horizontal_flip = True)\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale = 1./255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 64 images belonging to 3 classes.\n"
     ]
    }
   ],
   "source": [
    "# Make sure you provide the same target size as initialied for the image size\n",
    "training_set = train_datagen.flow_from_directory('Datasets/train',\n",
    "                                                 target_size = (224, 224),\n",
    "                                                 batch_size = 32,\n",
    "                                                 class_mode = 'categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 58 images belonging to 3 classes.\n"
     ]
    }
   ],
   "source": [
    "test_set = test_datagen.flow_from_directory('Datasets/test',\n",
    "                                            target_size = (224, 224),\n",
    "                                            batch_size = 32,\n",
    "                                            class_mode = 'categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "2/2 [==============================] - 5s 3s/step - loss: 2.2210 - acc: 0.3276\n",
      "2/2 [==============================] - 18s 9s/step - loss: 3.8136 - acc: 0.4531 - val_loss: 2.2210 - val_acc: 0.3276\n",
      "Epoch 2/50\n",
      "2/2 [==============================] - 5s 2s/step - loss: 7.0026 - acc: 0.3276\n",
      "2/2 [==============================] - 16s 8s/step - loss: 4.8997 - acc: 0.6562 - val_loss: 7.0026 - val_acc: 0.3276\n",
      "Epoch 3/50\n",
      "2/2 [==============================] - 5s 2s/step - loss: 10.4154 - acc: 0.3276\n",
      "2/2 [==============================] - 16s 8s/step - loss: 3.7128 - acc: 0.7656 - val_loss: 10.4154 - val_acc: 0.3276\n",
      "Epoch 4/50\n",
      "2/2 [==============================] - 5s 2s/step - loss: 10.8681 - acc: 0.3276\n",
      "2/2 [==============================] - 16s 8s/step - loss: 3.5485 - acc: 0.7656 - val_loss: 10.8681 - val_acc: 0.3276\n",
      "Epoch 5/50\n",
      "2/2 [==============================] - 5s 3s/step - loss: 10.8100 - acc: 0.3276\n",
      "2/2 [==============================] - 17s 9s/step - loss: 2.9154 - acc: 0.7969 - val_loss: 10.8100 - val_acc: 0.3276\n",
      "Epoch 6/50\n",
      "2/2 [==============================] - 5s 2s/step - loss: 10.8681 - acc: 0.3276\n",
      "2/2 [==============================] - 16s 8s/step - loss: 2.7595 - acc: 0.7500 - val_loss: 10.8681 - val_acc: 0.3276\n",
      "Epoch 7/50\n",
      "2/2 [==============================] - 5s 2s/step - loss: 10.6937 - acc: 0.3276\n",
      "2/2 [==============================] - 16s 8s/step - loss: 2.8718 - acc: 0.7812 - val_loss: 10.6937 - val_acc: 0.3276\n",
      "Epoch 8/50\n",
      "2/2 [==============================] - 5s 2s/step - loss: 10.8100 - acc: 0.3276\n",
      "2/2 [==============================] - 16s 8s/step - loss: 2.4052 - acc: 0.7969 - val_loss: 10.8100 - val_acc: 0.3276\n",
      "Epoch 9/50\n",
      "2/2 [==============================] - 5s 2s/step - loss: 10.9262 - acc: 0.3276\n",
      "2/2 [==============================] - 16s 8s/step - loss: 1.0581 - acc: 0.9062 - val_loss: 10.9262 - val_acc: 0.3276\n",
      "Epoch 10/50\n",
      "2/2 [==============================] - 5s 2s/step - loss: 10.8681 - acc: 0.3276\n",
      "2/2 [==============================] - 16s 8s/step - loss: 1.3668 - acc: 0.8750 - val_loss: 10.8681 - val_acc: 0.3276\n",
      "Epoch 11/50\n",
      "2/2 [==============================] - 5s 2s/step - loss: 10.8681 - acc: 0.3276\n",
      "2/2 [==============================] - 16s 8s/step - loss: 1.1777 - acc: 0.8906 - val_loss: 10.8681 - val_acc: 0.3276\n",
      "Epoch 12/50\n",
      "2/2 [==============================] - 5s 2s/step - loss: 10.8681 - acc: 0.3276\n",
      "2/2 [==============================] - 16s 8s/step - loss: 1.1361 - acc: 0.9062 - val_loss: 10.8681 - val_acc: 0.3276\n",
      "Epoch 13/50\n",
      "2/2 [==============================] - 5s 2s/step - loss: 10.7519 - acc: 0.3276\n",
      "2/2 [==============================] - 16s 8s/step - loss: 0.7172 - acc: 0.9219 - val_loss: 10.7519 - val_acc: 0.3276\n",
      "Epoch 14/50\n",
      "2/2 [==============================] - 5s 2s/step - loss: 10.6937 - acc: 0.3276\n",
      "2/2 [==============================] - 16s 8s/step - loss: 0.4897 - acc: 0.9531 - val_loss: 10.6937 - val_acc: 0.3276\n",
      "Epoch 15/50\n",
      "2/2 [==============================] - 5s 2s/step - loss: 10.8100 - acc: 0.3276\n",
      "2/2 [==============================] - 16s 8s/step - loss: 0.2518 - acc: 0.9844 - val_loss: 10.8100 - val_acc: 0.3276\n",
      "Epoch 16/50\n",
      "2/2 [==============================] - 5s 2s/step - loss: 10.9262 - acc: 0.3276\n",
      "2/2 [==============================] - 16s 8s/step - loss: 0.2518 - acc: 0.9844 - val_loss: 10.9262 - val_acc: 0.3276\n",
      "Epoch 17/50\n",
      "2/2 [==============================] - 5s 2s/step - loss: 10.7519 - acc: 0.3276\n",
      "2/2 [==============================] - 16s 8s/step - loss: 0.5408 - acc: 0.9531 - val_loss: 10.7519 - val_acc: 0.3276\n",
      "Epoch 18/50\n",
      "2/2 [==============================] - 5s 2s/step - loss: 10.6937 - acc: 0.3276\n",
      "2/2 [==============================] - 16s 8s/step - loss: 0.5061 - acc: 0.9688 - val_loss: 10.6937 - val_acc: 0.3276\n",
      "Epoch 19/50\n",
      "2/2 [==============================] - 5s 2s/step - loss: 10.7519 - acc: 0.3276\n",
      "2/2 [==============================] - 16s 8s/step - loss: 0.5637 - acc: 0.9531 - val_loss: 10.7519 - val_acc: 0.3276\n",
      "Epoch 20/50\n",
      "2/2 [==============================] - 5s 2s/step - loss: 10.9262 - acc: 0.3276\n",
      "2/2 [==============================] - 16s 8s/step - loss: 1.2342 - acc: 0.9062 - val_loss: 10.9262 - val_acc: 0.3276\n",
      "Epoch 21/50\n",
      "2/2 [==============================] - 5s 2s/step - loss: 11.0424 - acc: 0.3276\n",
      "2/2 [==============================] - 16s 8s/step - loss: 0.2518 - acc: 0.9844 - val_loss: 11.0424 - val_acc: 0.3276\n",
      "Epoch 22/50\n",
      "2/2 [==============================] - 5s 2s/step - loss: 10.8681 - acc: 0.3276\n",
      "2/2 [==============================] - 16s 8s/step - loss: 0.6671 - acc: 0.9531 - val_loss: 10.8681 - val_acc: 0.3276\n",
      "Epoch 23/50\n",
      "2/2 [==============================] - 5s 3s/step - loss: 10.9843 - acc: 0.3276\n",
      "2/2 [==============================] - 17s 9s/step - loss: 0.5037 - acc: 0.9688 - val_loss: 10.9843 - val_acc: 0.3276\n",
      "Epoch 24/50\n",
      "2/2 [==============================] - 5s 3s/step - loss: 10.7519 - acc: 0.3276\n",
      "2/2 [==============================] - 16s 8s/step - loss: 0.6528 - acc: 0.9531 - val_loss: 10.7519 - val_acc: 0.3276\n",
      "Epoch 25/50\n",
      "2/2 [==============================] - 5s 2s/step - loss: 11.1006 - acc: 0.3276\n",
      "2/2 [==============================] - 16s 8s/step - loss: 0.2519 - acc: 0.9844 - val_loss: 11.1006 - val_acc: 0.3276\n",
      "Epoch 26/50\n",
      "2/2 [==============================] - 5s 2s/step - loss: 10.9843 - acc: 0.3276\n",
      "2/2 [==============================] - 16s 8s/step - loss: 0.4941 - acc: 0.9688 - val_loss: 10.9843 - val_acc: 0.3276\n",
      "Epoch 27/50\n",
      "2/2 [==============================] - 5s 2s/step - loss: 10.6937 - acc: 0.3276\n",
      "2/2 [==============================] - 16s 8s/step - loss: 0.5037 - acc: 0.9688 - val_loss: 10.6937 - val_acc: 0.3276\n",
      "Epoch 28/50\n",
      "2/2 [==============================] - 5s 2s/step - loss: 11.0424 - acc: 0.3276\n",
      "2/2 [==============================] - 16s 8s/step - loss: 0.5037 - acc: 0.9688 - val_loss: 11.0424 - val_acc: 0.3276\n",
      "Epoch 29/50\n",
      "2/2 [==============================] - 5s 2s/step - loss: 10.8100 - acc: 0.3276\n",
      "2/2 [==============================] - 16s 8s/step - loss: 0.6007 - acc: 0.9531 - val_loss: 10.8100 - val_acc: 0.3276\n",
      "Epoch 30/50\n",
      "2/2 [==============================] - 5s 2s/step - loss: 10.8100 - acc: 0.3276\n",
      "2/2 [==============================] - 16s 8s/step - loss: 0.2518 - acc: 0.9844 - val_loss: 10.8100 - val_acc: 0.3276\n",
      "Epoch 31/50\n",
      "2/2 [==============================] - 5s 2s/step - loss: 10.7519 - acc: 0.3276\n",
      "2/2 [==============================] - 16s 8s/step - loss: 0.2519 - acc: 0.9844 - val_loss: 10.7519 - val_acc: 0.3276\n",
      "Epoch 32/50\n",
      "2/2 [==============================] - 5s 2s/step - loss: 10.9843 - acc: 0.3276\n",
      "2/2 [==============================] - 16s 8s/step - loss: 0.2518 - acc: 0.9844 - val_loss: 10.9843 - val_acc: 0.3276\n",
      "Epoch 33/50\n",
      "2/2 [==============================] - 5s 2s/step - loss: 11.0424 - acc: 0.3276\n",
      "2/2 [==============================] - 16s 8s/step - loss: 0.2518 - acc: 0.9844 - val_loss: 11.0424 - val_acc: 0.3276\n",
      "Epoch 34/50\n",
      "2/2 [==============================] - 5s 2s/step - loss: 10.6937 - acc: 0.3276\n",
      "2/2 [==============================] - 16s 8s/step - loss: 0.2518 - acc: 0.9844 - val_loss: 10.6937 - val_acc: 0.3276\n",
      "Epoch 35/50\n",
      "2/2 [==============================] - 6s 3s/step - loss: 10.8681 - acc: 0.3276\n",
      "2/2 [==============================] - 18s 9s/step - loss: 0.2963 - acc: 0.9688 - val_loss: 10.8681 - val_acc: 0.3276\n",
      "Epoch 36/50\n",
      "2/2 [==============================] - 5s 2s/step - loss: 10.8681 - acc: 0.3276\n",
      "2/2 [==============================] - 17s 8s/step - loss: 0.2518 - acc: 0.9844 - val_loss: 10.8681 - val_acc: 0.3276\n",
      "Epoch 37/50\n",
      "2/2 [==============================] - 5s 2s/step - loss: 10.9843 - acc: 0.3276\n",
      "2/2 [==============================] - 16s 8s/step - loss: 0.2518 - acc: 0.9844 - val_loss: 10.9843 - val_acc: 0.3276\n",
      "Epoch 38/50\n",
      "2/2 [==============================] - 5s 2s/step - loss: 10.9843 - acc: 0.3276\n",
      "2/2 [==============================] - 16s 8s/step - loss: 0.2518 - acc: 0.9844 - val_loss: 10.9843 - val_acc: 0.3276\n",
      "Epoch 39/50\n",
      "2/2 [==============================] - 5s 3s/step - loss: 10.7519 - acc: 0.3276\n",
      "2/2 [==============================] - 17s 9s/step - loss: 0.0954 - acc: 0.9844 - val_loss: 10.7519 - val_acc: 0.3276\n",
      "Epoch 40/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 5s 3s/step - loss: 10.8681 - acc: 0.3276\n",
      "2/2 [==============================] - 18s 9s/step - loss: 0.1648 - acc: 0.9844 - val_loss: 10.8681 - val_acc: 0.3276\n",
      "Epoch 41/50\n",
      "2/2 [==============================] - 5s 3s/step - loss: 10.7519 - acc: 0.3276\n",
      "2/2 [==============================] - 17s 8s/step - loss: 0.3605 - acc: 0.9688 - val_loss: 10.7519 - val_acc: 0.3276\n",
      "Epoch 42/50\n",
      "2/2 [==============================] - 5s 2s/step - loss: 11.0424 - acc: 0.3276\n",
      "2/2 [==============================] - 17s 8s/step - loss: 0.0916 - acc: 0.9844 - val_loss: 11.0424 - val_acc: 0.3276\n",
      "Epoch 43/50\n",
      "2/2 [==============================] - 5s 2s/step - loss: 10.9262 - acc: 0.3276\n",
      "2/2 [==============================] - 16s 8s/step - loss: 0.1308 - acc: 0.9844 - val_loss: 10.9262 - val_acc: 0.3276\n",
      "Epoch 44/50\n",
      "2/2 [==============================] - 5s 2s/step - loss: 10.6937 - acc: 0.3276\n",
      "2/2 [==============================] - 16s 8s/step - loss: 0.2518 - acc: 0.9844 - val_loss: 10.6937 - val_acc: 0.3276\n",
      "Epoch 45/50\n",
      "2/2 [==============================] - 5s 2s/step - loss: 10.8681 - acc: 0.3276\n",
      "2/2 [==============================] - 16s 8s/step - loss: 1.2666e-07 - acc: 1.0000 - val_loss: 10.8681 - val_acc: 0.3276\n",
      "Epoch 46/50\n",
      "2/2 [==============================] - 5s 3s/step - loss: 10.8100 - acc: 0.3276\n",
      "2/2 [==============================] - 17s 8s/step - loss: 1.1921e-07 - acc: 1.0000 - val_loss: 10.8100 - val_acc: 0.3276\n",
      "Epoch 47/50\n",
      "2/2 [==============================] - 5s 2s/step - loss: 10.8100 - acc: 0.3276\n",
      "2/2 [==============================] - 16s 8s/step - loss: 5.9376e-04 - acc: 1.0000 - val_loss: 10.8100 - val_acc: 0.3276\n",
      "Epoch 48/50\n",
      "2/2 [==============================] - 5s 2s/step - loss: 10.9262 - acc: 0.3276\n",
      "2/2 [==============================] - 16s 8s/step - loss: 0.0049 - acc: 1.0000 - val_loss: 10.9262 - val_acc: 0.3276\n",
      "Epoch 49/50\n",
      "2/2 [==============================] - 5s 3s/step - loss: 10.8681 - acc: 0.3276\n",
      "2/2 [==============================] - 16s 8s/step - loss: 0.2458 - acc: 0.9844 - val_loss: 10.8681 - val_acc: 0.3276\n",
      "Epoch 50/50\n",
      "2/2 [==============================] - 5s 2s/step - loss: 10.9843 - acc: 0.3276\n",
      "2/2 [==============================] - 16s 8s/step - loss: 1.1921e-07 - acc: 1.0000 - val_loss: 10.9843 - val_acc: 0.3276\n"
     ]
    }
   ],
   "source": [
    "# fit the model\n",
    "# Run the cell. It will take some time to execute\n",
    "r = model.fit_generator(\n",
    "  training_set,\n",
    "  validation_data=test_set,\n",
    "  epochs=50,\n",
    "  steps_per_epoch=len(training_set),\n",
    "  validation_steps=len(test_set)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'loss': [4.897270679473877,\n",
       "  3.0943384170532227,\n",
       "  3.944007635116577,\n",
       "  1.7115281820297241,\n",
       "  0.6133597493171692,\n",
       "  0.9116775691509247,\n",
       "  0.33869357209187,\n",
       "  0.5686702877283096,\n",
       "  0.25849587126867846,\n",
       "  0.0018636072636581957,\n",
       "  9.47606372392329e-06,\n",
       "  3.352774911036249e-07,\n",
       "  2.0815722763245503e-06,\n",
       "  0.13719143159777047,\n",
       "  0.00103764608502388,\n",
       "  0.17998312413692474,\n",
       "  0.005726777657400817,\n",
       "  4.240815542289056e-06,\n",
       "  1.1920928955078125e-07,\n",
       "  0.0014061930123716593,\n",
       "  3.9395118278662267e-07,\n",
       "  3.95384086004924e-06,\n",
       "  4.535577033948357e-07,\n",
       "  1.1920928955078125e-07,\n",
       "  0.02212175726890564,\n",
       "  1.1920928955078125e-07,\n",
       "  1.1920928955078125e-07,\n",
       "  0.00020595203386619687,\n",
       "  0.00789467804133892,\n",
       "  3.681924681586679e-06,\n",
       "  0.0318756438791894,\n",
       "  1.1920928955078125e-07,\n",
       "  1.1920928955078125e-07,\n",
       "  1.7695140286377864e-07,\n",
       "  1.1920928955078125e-07,\n",
       "  1.1920928955078125e-07,\n",
       "  1.1920928955078125e-07,\n",
       "  1.1920928955078125e-07,\n",
       "  4.4890100525663e-07,\n",
       "  1.1920928955078125e-07,\n",
       "  0.10256899148225784,\n",
       "  1.1920928955078125e-07,\n",
       "  1.1920928955078125e-07,\n",
       "  3.203762730663584e-07,\n",
       "  0.07348173047648743,\n",
       "  0.016421398371676332,\n",
       "  1.1920928955078125e-07,\n",
       "  1.4994297004022883e-07,\n",
       "  1.1920928955078125e-07,\n",
       "  1.3411045785005626e-07],\n",
       " 'acc': [0.359375,\n",
       "  0.671875,\n",
       "  0.625,\n",
       "  0.859375,\n",
       "  0.921875,\n",
       "  0.921875,\n",
       "  0.96875,\n",
       "  0.9375,\n",
       "  0.96875,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.984375,\n",
       "  1.0,\n",
       "  0.984375,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.984375,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.984375,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.96875,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.984375,\n",
       "  0.984375,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0],\n",
       " 'val_loss': [3.5185288190841675,\n",
       "  10.728153705596924,\n",
       "  10.807278156280518,\n",
       "  10.693736553192139,\n",
       "  10.868090629577637,\n",
       "  10.984327793121338,\n",
       "  10.868090629577637,\n",
       "  10.926209449768066,\n",
       "  11.042445659637451,\n",
       "  10.984327793121338,\n",
       "  10.635618209838867,\n",
       "  10.868090629577637,\n",
       "  10.69373607635498,\n",
       "  10.868090629577637,\n",
       "  10.69373607635498,\n",
       "  10.926209449768066,\n",
       "  10.809972763061523,\n",
       "  10.926209449768066,\n",
       "  10.809972763061523,\n",
       "  10.868091106414795,\n",
       "  10.868091106414795,\n",
       "  10.751854419708252,\n",
       "  10.868090629577637,\n",
       "  10.926209449768066,\n",
       "  10.926209449768066,\n",
       "  10.809972763061523,\n",
       "  10.926209449768066,\n",
       "  10.751854419708252,\n",
       "  10.926209449768066,\n",
       "  10.926209449768066,\n",
       "  10.984326362609863,\n",
       "  10.868091106414795,\n",
       "  10.751854419708252,\n",
       "  10.751854419708252,\n",
       "  10.926209449768066,\n",
       "  10.809972763061523,\n",
       "  10.809973239898682,\n",
       "  10.868090629577637,\n",
       "  10.751854419708252,\n",
       "  10.98432731628418,\n",
       "  10.69373607635498,\n",
       "  10.926209449768066,\n",
       "  10.868090629577637,\n",
       "  10.926209449768066,\n",
       "  10.809972763061523,\n",
       "  10.868091106414795,\n",
       "  10.69373607635498,\n",
       "  10.868091106414795,\n",
       "  10.868090629577637,\n",
       "  10.809972763061523],\n",
       " 'val_acc': [0.3275862,\n",
       "  0.3275862,\n",
       "  0.3275862,\n",
       "  0.3275862,\n",
       "  0.3275862,\n",
       "  0.3275862,\n",
       "  0.3275862,\n",
       "  0.3275862,\n",
       "  0.3275862,\n",
       "  0.3275862,\n",
       "  0.3275862,\n",
       "  0.3275862,\n",
       "  0.3275862,\n",
       "  0.3275862,\n",
       "  0.3275862,\n",
       "  0.3275862,\n",
       "  0.3275862,\n",
       "  0.3275862,\n",
       "  0.3275862,\n",
       "  0.3275862,\n",
       "  0.3275862,\n",
       "  0.3275862,\n",
       "  0.3275862,\n",
       "  0.3275862,\n",
       "  0.3275862,\n",
       "  0.3275862,\n",
       "  0.3275862,\n",
       "  0.3275862,\n",
       "  0.3275862,\n",
       "  0.3275862,\n",
       "  0.3275862,\n",
       "  0.3275862,\n",
       "  0.3275862,\n",
       "  0.3275862,\n",
       "  0.3275862,\n",
       "  0.3275862,\n",
       "  0.3275862,\n",
       "  0.3275862,\n",
       "  0.3275862,\n",
       "  0.3275862,\n",
       "  0.3275862,\n",
       "  0.3275862,\n",
       "  0.3275862,\n",
       "  0.3275862,\n",
       "  0.3275862,\n",
       "  0.3275862,\n",
       "  0.3275862,\n",
       "  0.3275862,\n",
       "  0.3275862,\n",
       "  0.3275862]}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXAAAAD4CAYAAAD1jb0+AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8qNh9FAAAACXBIWXMAAAsTAAALEwEAmpwYAAAvFElEQVR4nO3dd3xUVf7/8ddJ74WQkJCACUVKCAQICEZAsIEKYteVBfu6a1l1111cv7vqd/Ur67quZS3LKpa1wQ8bKoqIAoKAhia9lzTSK6mTOb8/7oSEkIQkM5Phznyej0cek8zcufdzJzPve+6Ze89VWmuEEEKYj5erCxBCCNE1EuBCCGFSEuBCCGFSEuBCCGFSEuBCCGFSPt25sJ49e+rExMTuXKQQQpjexo0bC7XW0S3v79YAT0xMJCMjozsXKYQQpqeUOtLa/dKFIoQQJiUBLoQQJiUBLoQQJiUBLoQQJiUBLoQQJiUBLoQQJiUBLoQQJiUBLjxT9kbIWAAVx1xdiRBd1q0n8ghxWg0WOLIWynNg6BXgF+T4ZRxeA+9eC/VV8PmD0Hc8JF8JQ2dAaGzn5qU17PgYYlOg50DH19rWMivzIH8XFB+A/lOgR7/uWXZ3slph16cQFAVnpYOXt6srOuOo7rygQ1pampYzMcUpGkN75yewcwlUFRr3B0dD+v2Qdmv7QV6RB4e/N4I4PL79ZTWGd3gfmPECHFwJOz6Bgl2AMuYx/DoYNQe8TrODqjV88xisfQ68/WHKIzD+HscHjaUWtrwLuVshf7dRa01Z0+NBUTDnM+iV7NjlgrEh3bcc6o63/ni/Sc5Zbm0lfPwr2P258XdwNAyZAckzzRXmWkPeDtizFM57ELy71mZWSm3UWqedcr8EeDepLoWD34FfCEQPMgJEKVdX1TqtIWcTVBUbrTtnfViyNsKWd5pC2zcIzr4Ehs6EoB7w/T+MgG0tyCvyYNcS2PmpEcpo8A+DS56Ekb9s/bVtHt43fw4hMU2PFewxgnzHx0ZADr4crvw3+Ie0Xnvz8B4123itdn8O8Wkw8xWIPtsxr1H2RvjkN1CwGwIjIXoIxAyGaNuPfwh8MAsaah0X4uU5xv9k5ydwdD3QTkZ4+cCE38GE34OPn/3LBijNhPdvhPwdcPETEBZv/F/2fW3sNTWGedqtEDvMMcvsKEsdHF5tbNCiBxt7Pt6+J0/TGNo7PzHeU0X7QHnBHd9C75FdWqwEeKOjG8BqgZghRki0RWsozzY+OH6h0Gds5wO3uhT2fGn8I/evAGt902N+IdDzbKOO6MEQ3BPoxPz9giBpEgRGdK6mtjSG9o5PjHpLjxr3Rw2ESX+EYVc5LsizMmDlPNi/vCm0k6+EARed2tI+sg5WzWsK8tRfQPamptDuOch4bmI6rHraaIn3v8BoXYcnNM2nvfBu+Tps+DcsexhikuHG9yGiz6nTNIZ32m1w6TPGe2P7h7D0IePDPflPcO69XX/NLLWw8ilY+zyExBrrM+DC1t+DRQfgzcuNEJ+9pP1QK8009nZa+9xXFRkbocbQjkk2WrxD2uhaqq8yXoefF0KvYTDzZYgb0fayC/cbXT5npbe9Ycz8ET64CSw1cM0bMPDCpsfqjht7A41hbqk1Nh4THzr9xuN4IRz5ASITjc+db0D70zdnqYNDq4zPxu7Poaa06TEvX4ga0LRRbag3GhWNoZ14ntEgGTIDQk4Zi6rDJMABtn5g7JY1Co5uaslEDzLeNAW7bbupe6CuomnavufC+XMhaWL7Qd5aaIf3Mfpzh8wAbTVaePm7jWUV7Db6M7vC289oIQ+dCYOmdT7MWwttL1/oP9mYp28ArH4G8nc6JsibB3dgD0i/D8bcDv6hp39u8yBvDO3kmcYGsJHVChmvw/JHjRobW+NH1nYsvJvb9w0svgV8/OGG94wNOLQe3s27Wirz4fMHmlrj437d+uvVuAEP73NqV03zVvfIWXDxk6f/354uxEszYc2zsOm/JzckWmoM7aEzO74XsXspfH6/sQFo2Rov3A87P4Ydn0LeNuM+n0AYeJGxnIGXNIX51oWw5B6jxf2LhcZnsi1VxfDVw/DzB0bNM1+G3qmnTne8EH54AX78j7HBASNYIxONvZnoQW0HekM9HFzVFNr+YTDoUuO9FxprZMSJz/IuKDliZIODQrs5CfC8HfCfCyB+NEx4oOlFL9hj/N4Y1sExxj81xvbPjR4MeTuNN39FbutB3l5oJ19pLLO90K8qPrlPsyMq82DXZ0b4lmcZwTvgAmOZ8WnQI+nUXTs4fWgPvtTYVW9ktRpdFav+1hTkE2xf/EWcdfp+4soCOLYV1r/aIrjvaLsV1p7q0tOHWfEhWHKv0Ro/6zxjfTsT3o0K9sB71xt7YjP+ZfSNtxfejbRuao1XF7e/DN/gpvdZzGBjA7D+5aZW98CLOl5vayHePLjB6O4Zc5ux59OSTwCExXV8ec1VFcNXc5ta44Mvh91fNIV2n3NsG4VBxmdl1xLjPewTaLSyg3rCxjcgcQJc93b7e8fN7fkSPvutEdTNW+MnBXc1pFwDo28xltkYvAV7oGi/sUfeluah3X+ysUFvS10VNNQ5bq+4Gc8O8JoymD/Z2AX71WoI7XXy41ob/X4+ARAc1fo86mtg09snB3nylXBgxamhPXQmJKR1Tx+31kbLtrG/rTzLuN/L1zgqInqwsTGK6g85W5qFtk9T671laLemZZCD8eGLPrupX7ZH/6ajIxr3LqqKjGntDe7Oat4aD0/ofHg3qiqGRbNtX5KeC0d/aD+8m6spN8K/NdWltteoWSuu0nZIY0db3a1pDHFLjfF/3brQuH/UbDjvgVO7gxytsTVemdcU2kNnnNydBWBtMLpqdnzcFOaj5hiva2f70lu2xvtNgo1vNgX3xIfabs1b6ozPQ6t7JcpoCLUX2t3EcwNca1j0S+ONdfPncNa59s2vZZB3pqXtbFrDsW1GwDYP0ZIjgDZCu99ko9aOhHZrrFZjFz9/Z9P883dDRU7TNP7hJ3/RFjMYEsZ2T3C3dLwIfAPtOxyxoR6W/t4IhY6Gd1dUlxihH3mWffNpDPHjBd0X3M3VVRmNpY52H1gbjAAPjbPv89PYGq/MP31wm4znBvgP/4KvH4GL/mq0AB2lvsbYcvcceOYeTdKo7rjxoY7o07XQ7ojqUig+aHwIQ2PP/Neks7Q21q9HP3OsW1WxseFpubfp7moroa6y88fzn+HaCnD3PpHnyDpY/hcYMt04IsCRfAMcd6iYs/kFQ9xw5y4jMALiRzl3Ga6klNENZRYd7UN2N/4hrtnTcxH3PZW+Mh/+383G7ugVL5mj1SSEEJ3gni3wBgssvtX48nLWhxAQ7uqKhBDC4dwzwA+tNI4amP5895+pJYQQ3cQ9u1BKM43bARe2P50QQpiYewZ4xTFAQYiHfQMvhPAobhrgOcZp8q2diSiEEG7CTQP8mNsdByqEEC2dNsCVUguUUvlKqe3N7uuhlFqulNpnu3XS2SFdVJFrnFAihBBurCMt8DeBqS3umwus0FoPBFbY/j5zSAtcCOEBThvgWuvVQMsh1a4A3rL9/hYw07Fl2aGh3hgDIqy3qysRQgin6mofeC+tda7t92NAm4d7KKXuVEplKKUyCgoKuri4TmgcW1ta4EIIN2f3l5jaGA2rzRGxtNbztdZpWuu06GjHDG7ersarjEsfuBDCzXU1wPOUUnEAttt8x5Vkp3LbsKbSAhdCuLmuBvgSYI7t9znAp44pxwGkBS6E8BAdOYzwfWAdMEgplaWUug2YB1yklNoHXGj7+8xQkWtcuCCop6srEUIIpzrtYFZa6xvbeOgCB9fiGBXHjOsJOuOKKUIIcQZxv5SryJX+byGER3DDAJeTeIQQnsENAzxHvsAUQngE9wrwuirjKjzSAhdCeAD3CvBKOYRQCOE53CvAG48BD5MAF0K4PzcLcNvwLNICF0J4ADcL8MYuFOkDF0K4P/cK8PIc8AmAgAhXVyKEEE7nXgHeeAy4Uq6uRAghnM4NA1wu5CCE8AxuFuByGr0QwnO4T4BrbWuByxEoQgjP4D4BXlsB9celBS6E8BjuE+ByIQchhIdxowCXS6kJITyLGwV442n0chSKEMIzuFGA206jD+nl2jqEEKKbuFGAHwP/MPAPcXUlQgjRLdwowOUYcCGEZ3GjAJdLqQkhPIv7BHh5rpxGL4TwKO4R4FpLF4oQwuO4R4BXFYO1Xk7iEUJ4FPcI8BNX4pEWuBDCc7hJgMtp9EIIz2NXgCulHlBK7VBKbVdKva+UCnBUYZ0iLXAhhAfqcoArpeKB+4A0rfUwwBu4wVGFdYoEuBDCA9nbheIDBCqlfIAgIMf+krqgIheCosDH3yWLF0IIV+hygGuts4FngKNALlCmtf665XRKqTuVUhlKqYyCgoKuV9oeuZCDEMID2dOFEglcASQBvYFgpdSsltNpredrrdO01mnR0dFdr7Q9cgy4EMID2dOFciFwSGtdoLWuBz4CznVMWZ0kp9ELITyQPQF+FBinlApSSingAmCXY8rqBGsDVOZJF4oQwuPY0we+AVgMbAK22eY130F1ddzxAtBWCXAhhMfxsefJWutHgUcdVEvXlDdeSk0CXAjhWcx/JuaJszClD1wI4VncIMAbT+KRFrgQwrO4QYAfA+UFwU46RFEIIc5QbhDgucaFjL3t6s4XQgjTcYMAl2PAhRCeyQ0CPFf6v4UQHslNAlxa4EIIz2PuALfUQlWRtMCFEB7J3AFemWfcSgtcCOGBzB3gJ07i6e3aOoQQwgVMHuByJR4hhOcyd4CXy1mYQgjPZe4AP54PXj4Q1MPVlQghRLczd4BXFUNgJCjl6kqEEKLbmTvAq4shUFrfQgjPZPIALzFa4EII4YHMHeBVJdL/LYTwWOYOcOlCEUJ4MJMHeAkERri6CiGEcAnzBnh9DdRXSReKEMJjmTfAq4uNW+lCEUJ4KBMHeIlxK0ehCCE8lHmvQ1Zla4FLF4oQZ4T6+nqysrKoqalxdSmmFRAQQEJCAr6+vh2a3rwBLl0oQpxRsrKyCA0NJTExESVnR3ea1pqioiKysrJISkrq0HOkC0UI4RA1NTVERUVJeHeRUoqoqKhO7cGYN8ClC0WIM46Et306+/qZN8Cri8EnEHwDXV2JEOIMUFpayssvv9yl51566aWUlpZ2ePrHHnuMZ555pkvLciS7AlwpFaGUWqyU2q2U2qWUGu+owk5LxkERQjTTXoBbLJZ2n7t06VIiIiKcUJVz2dsCfx74Sms9GBgB7LK/pA6ScVCEEM3MnTuXAwcOkJqaykMPPcTKlSuZMGECM2bMYOjQoQDMnDmT0aNHk5yczPz58088NzExkcLCQg4fPsyQIUO44447SE5O5uKLL6a6urrd5W7ZsoVx48YxfPhwrrzySkpKjO/nXnjhBYYOHcrw4cO54YYbAFi1ahWpqamkpqYycuRIKioq7FrnLh+FopQKByYCNwNoreuAOruq6YzqYmmBC3GGevyzHezMKXfoPIf2DuPR6cltPj5v3jy2b9/Oli1bAFi5ciWbNm1i+/btJ47qWLBgAT169KC6upoxY8Zw9dVXExUVddJ89u3bx/vvv89//vMfrrvuOj788ENmzZrV5nJnz57Niy++yKRJk/jLX/7C448/znPPPce8efM4dOgQ/v7+J7pnnnnmGV566SXS09OprKwkICDArtfEnhZ4ElAAvKGU2qyUek0pFdxyIqXUnUqpDKVURkFBgR2La0G6UIQQpzF27NiTDsl74YUXGDFiBOPGjSMzM5N9+/ad8pykpCRSU1MBGD16NIcPH25z/mVlZZSWljJp0iQA5syZw+rVqwEYPnw4N910E++88w4+PkZbOT09nQcffJAXXniB0tLSE/d3lT3P9gFGAfdqrTcopZ4H5gJ/bj6R1no+MB8gLS1N27G8k1UVSxeKEGeo9lrK3Sk4uKlNuXLlSr755hvWrVtHUFAQ559/fquH7Pn7+5/43dvb+7RdKG354osvWL16NZ999hlPPvkk27ZtY+7cuVx22WUsXbqU9PR0li1bxuDBg7s0f7CvBZ4FZGmtN9j+XowR6M6ntQwlK4Q4SWhoaLt9ymVlZURGRhIUFMTu3btZv3693csMDw8nMjKS77//HoD//ve/TJo0CavVSmZmJpMnT+Zvf/sbZWVlVFZWcuDAAVJSUvjjH//ImDFj2L17t13L73ILXGt9TCmVqZQapLXeA1wA7LSrmo6qqwSrRbpQhBAnREVFkZ6ezrBhw5g2bRqXXXbZSY9PnTqVV199lSFDhjBo0CDGjRvnkOW+9dZb3HXXXVRVVdGvXz/eeOMNGhoamDVrFmVlZWitue+++4iIiODPf/4z3333HV5eXiQnJzNt2jS7lq207nqvhlIqFXgN8AMOArdorUvamj4tLU1nZGR0eXknlByB54fDFS/ByLa/XBBCdJ9du3YxZMgQV5dheq29jkqpjVrrtJbT2tWDrrXeApwyU6eTcVCEEMKkZ2LKOChCCGHSAJdxUIQQwqQBfqIFLgEuhPBcJg/wCJeWIYQQrmTOAK8qBv8w8O7YVSuEEMIdmTPAZRwUIYQDhISEdOr+M41JA1zGQRFCCHMGuIyDIoRoYe7cubz00ksn/m686EJlZSUXXHABo0aNIiUlhU8//bTD89Ra89BDDzFs2DBSUlJYuHAhALm5uUycOJHU1FSGDRvG999/T0NDAzfffPOJaf/5z386fB1bMudFjauLITLR1VUIIdry5Vw4ts2x84xNgWnz2nz4+uuv5/777+fuu+8GYNGiRSxbtoyAgAA+/vhjwsLCKCwsZNy4ccyYMaNDly/76KOP2LJlC1u3bqWwsJAxY8YwceJE3nvvPS655BIeeeQRGhoaqKqqYsuWLWRnZ7N9+3aATl3hp6tMGuDShSKEONnIkSPJz88nJyeHgoICIiMj6dOnD/X19fzpT39i9erVeHl5kZ2dTV5eHrGxsaed55o1a7jxxhvx9vamV69eTJo0iZ9++okxY8Zw6623Ul9fz8yZM0lNTaVfv34cPHiQe++9l8suu4yLL77Y6etsvgC3NkB1qXShCHEma6el7EzXXnstixcv5tixY1x//fUAvPvuuxQUFLBx40Z8fX1JTEzs1JXfWzNx4kRWr17NF198wc0338yDDz7I7Nmz2bp1K8uWLePVV19l0aJFLFiwwBGr1Sbz9YHXlAFaWuBCiFNcf/31fPDBByxevJhrr70WMIaRjYmJwdfXl++++44jR450eH4TJkxg4cKFNDQ0UFBQwOrVqxk7dixHjhyhV69e3HHHHdx+++1s2rSJwsJCrFYrV199NU888QSbNm1y1mqeYL4WeFXTQFZaa6wavL1O35clhHB/ycnJVFRUEB8fT1xcHAA33XQT06dPJyUlhbS0tE5dQOHKK69k3bp1jBgxAqUUTz/9NLGxsbz11lv8/e9/x9fXl5CQEN5++22ys7O55ZZbsFqtADz11FNOWcfm7BpOtrMcMpxs5k/w+oVw02LeyB/AKysPsPoPkwnw9XZMkUKILpHhZB2jM8PJmq8L5cRQspEs3phFfkUt6w8WubYmIYRwAfMFuK0LJbcukB22q15/tzvflRUJIYRLmC/AbQNZfX2oHoAhcWF8uyef7uwKEkKIM4EJA7wYlBef7alkaFwYs8b1JbO4mgMFla6uTAiPJw0p+3T29TNfgFcVY/WPIONoGVOHxTJ5UAwAK3ZJN4oQrhQQEEBRUZGEeBdprSkqKiIgIKDDzzHfYYTVJVR4hQIwdVgsvSMCGRwbyre78/nVpP4uLk4Iz5WQkEBWVhYFBQWuLsW0AgICSEhI6PD0JgzwYvItQfSLDmZgjDHk45TBMfx79UHKqusJD5QxwoVwBV9fX5KSklxdhkcxXReKpbKIzJoApibHnhiM5oIhMTRYNd/vky2/EMJzmC7AayuKKNEhTB3WNBBNap9IIoN8+Vb6wYUQHsR0Ae5dU4LFL4KU+PCm+7wUk86OZuXeAhqs8gWKEMIzmCrAK6uqCNDVxPSKO2Us38mDYyg+XsfWrFLXFCeEEN3MVAG+bvs+AJL69DnlsUlnR+PtpeSsTCGExzBVgG/YsR+AvgnxpzwWEeTH6L6Rcjy4EMJj2B3gSilvpdRmpdTnjiioLTX1Dew9ZIzj69XGxRwmD45hZ245x8rsG6xdCCHMwBEt8N8Cuxwwn3at3V9IgMUYvKqtq/FMGWyclfndHmmFCyHcn10BrpRKAC4DXnNMOW37cvsx4vyqjT/auBrP2b1CiI8I5FvpBxdCeAB7W+DPAX8ArG1NoJS6UymVoZTK6OoptvUNVr7ZlUdajO0QwcDWW+BKKaYMjmHNvkJq6hu6tCwhhDCLLge4UupyIF9rvbG96bTW87XWaVrrtOjo6C4t68dDxZRW1ZMcaQVvP/ALbnPaKYNjqK5vYMOh4i4tSwghzMKeFng6MEMpdRj4AJiilHrHIVW18NX2YwT6etM3sMboPlFtXwNzfP8oAny95HBCIYTb63KAa60f1lonaK0TgRuAb7XWsxxWWTNB/t7MHNkbn5qSNrtPGgX4enNu/56s2J0nw1oKIdyaKY4Df3jaEJ66ajhUl7Z5BEpzUwbHkFlczRNf7CKvXA4pFEK4J4cEuNZ6pdb6ckfMq13VxW0egdLcVaPimZnamzfWHmLC377j4Y9+5nDhcaeXJ4QQ3ckULfATqjoW4EF+Pjx3w0hW/n4y16Yl8OGmbKb8YyV3v7eJ7dll3VCoEEI4n3kCXGvjgsYd6EJp1DcqiCevTGHNHydz58T+rNpTwOUvrmFRRqYTCxVCiO5hngCvr4KG2g61wFuKCQ1g7rTBrJ07hdFnRfL0V7uprLU4oUghhOg+5gnwKttx3ac5CqU94YG+/PnyoRRW1vHvVQccVJgQQriGeQK8usS47UQXSmtS+0Rw+fA4/vP9QRn0SghhaiYK8MYWeOe7UFr6wyWDabBqnl2+x+55CSGEq5gnwB3QhdKob1QQs8cn8v82ZrH7WLnd8xNCCFcwT4A7qAul0b1TBhDq78NTS3c7ZH5CCNHdTBTgjutCAeMKPvdMGcCqvQWs2VfokHkKIUR3Mk+AV5WAbzD4+DtslrPHJxIfEciTS3fJ1eyFEKZjngDv5Ek8HRHg680fpg5iV245H2/Odui8hRDC2UwU4MUQGOHw2U4f3puU+HD+8fUeuQiEEMJUzBPgVcUOOQKlJS8vxZ8uHUJuWQ1zP/yZrJIqhy9DCCGcwcfVBXRYdQmExztl1uP7R3HHhCQWrD3MZz/nMm1YLLdP6Edqn4hTps0prWbZjmN8uf0YeeU1vHfHOOIjAp1SlxBCtMdEAd6xkQi76pHLhnJLehJv/nCY9zcc5fOfcxmTGMlt5/Xj7F4hLNuRx1c7jrE1sxSAQb1CKayo5d73NrHwV+Px9TbPzowQwj2YI8CtVqMF7oQulOZ6RwTyp0uHcN8FA1n0UyYL1h7irneaLvk5PCGcP0wdxNTkWPpFh7Bkaw73vb+ZZ77ew8PThji1NiGEaMkcAV5bDtrq8KNQ2hLi78Ot5yUxe/xZLN+ZR0FlLVMGx5AQGXTSdDNG9Gb9wSL+veog5yT1YMrgXt1SnxBCgFm+xHTwSTwd5ePtxbSUOGaPTzwlvBv95fKhDIkL43eLtpJTWt2t9QkhPJs5ArzKdhq9k7tQuiLA15uXfjGSOouV+97fTH2D1dUlCSE8hDkC3MHjoDhav+gQ/u+qFDKOlPDs8r2uLkcI4SFMEuCu6ULpjCtS47lxbB9eWXmAlXvyXV2OEMIDmCPAHTiUrDM9Oj2ZwbGhPLhoKwUVta4uRwjh5swR4I1dKE44ld6RAny9+cd1Iyg+XseyHcdcXY4Qws2ZJMCLISAcvLxdXclpDY0LIy48gHUHilxdihDCzZkjwJ00DoozKKUY3z+KdQeLsMoQtUIIJzJHgDthKFlnSu/fk+LjdezJq3B1KUIIN9blMzGVUn2At4FegAbma62fd1RhJ7nmdag3z0ky4/tHAbB2fyFD4sJcXI0Qwl3Z0wK3AL/TWg8FxgF3K6WGOqasFgIjIay3U2btDL0jAknqGSz94EIIp+pygGutc7XWm2y/VwC7AOeM92pC4/tHseFQMRY5M1MI4SQO6QNXSiUCI4ENrTx2p1IqQymVUVBQ4IjFmUJ6/55U1lr4ObvM1aUIIdyU3QGulAoBPgTu11qXt3xcaz1fa52mtU6Ljo62d3GmMa6f8aWrdKMIIZzFrgBXSvlihPe7WuuPHFOSe4gK8WdwbCg/HCh0dSlCCDfV5QBXSingdWCX1vpZx5XkPs7t35OMwyVysWQhhFPY0wJPB34JTFFKbbH9XOqgutxC+oAoai1WNh0tcXUpQgg31OXjwLXWawDlwFrcztikHnh7KdYdKOLc/j1dXY4Qws2Y40xMkwoN8CUlPpwf5ItMIYQTSIA7WfqAKLZmllJZa3F1KUIINyMB7mTn9u+Jxar56VCxq0sRQrgZCXAnG31WJH7eXnI4oRDC4STAnSzA15tRZ0Wwdn/b/eAVNfVU1UkXixCicyTAu0F6/57szC2n5HjdKY9tyypj8jOrSJ/3La+vOUStRY4ZF0J0jAR4Nzh3gDG87PqDJ7fCV+7J5/r56/D38SK5dzh//XwnF/xjFZ9uyZaLQQghTksCvBsMT4ggyM+btc36wRdlZHLbWxkk9Qzm49+cyzu3n8N/bxtLWIAvv/1gC9P/tYbv97n34F8L1hzi2a/3uLoMIUyryyfyiI7z9fZibFIPfjhQhNaaF1bs55/f7GXCwJ68Mms0If7Gv2HCwGjS7+3Jkq05PPP1Hn75+o8MjQujX3Qw8ZGBJEQE0jsikPjIQPpEBhHsb95/X05pNfO+3I1Va25OT6JHsJ+rSxLCdMybACaT3r8nK/fs4p73N/PFz7lcPSqBeVen4Ot98k6Ql5di5sh4pqXE8s76o6zYlce27DK+3pFHXbOxxYP9vHn7tnMYfVZkd6+KQ7z47T4sVitWDV/8nMMvxye6uiQhTEdp3X19rWlpaTojI6Pblncm2Z5dxuUvrgHg3ikDePCiszHGA+sYq1VTWFlLdmk12aXV/H3ZHo7XWvj0nvOIjwh0VtlOcbjwOBc8u4pZ5/Rl/cFiQgJ8+PDX57q6LCHOWEqpjVrrtJb3Sx94NxkaF8ZVo+J5+urh/O7iQZ0KbzBa5jFhAYzsG8nlw3vz+pw0auut3P5WBsdNdpbnc9/sxddbcfeUAcxI7c3GIyVkFle5uiwhTEcCvJt4eSmevS6V68b0ccj8BsSE8uIvRrLnWDkPLNximqNW9hyr4NOtOcw5N5GY0ACuSDWudbpka46LKxPCfCTATez8QTH8z2VD+XpnHv9Ybo6jOZ5dvocQPx/umtgfgITIIMYkRvLJ5my6sztPCHcgAW5yt6QncuPYPrz03QE+3pzl6nLa9XNWKct25HHbhCQimx11ckVqPPvyK9mZe8oV+YQQ7ZAANzmlFI/PGMY5ST3444fbzuiLRzzz9V4ig3y57bykk+6/LCUOHy/Fp1ukG0WIzpAAdwN+Pl68Oms0sWEB3Pn2RnadgS3ZDQeLWL23gF+f35/QAN+THosM9uP8QdEs2ZJDg0n68oU4E0iAu4nIYD9en5MGaKa/uIZnl++lzmI97fO6g9aaZ77eQ0yoP7PbON77itR4jpXXsOFQ24N+ZRZX8eDCLXy1/ViHvrSts1hZui33jNygCeEIciKPGxnYK5SvH5jE/362gxdW7OOr7bk8fc0IUvtEuLSuVXsL+OlwCX+9IpkAX+9Wp7lwSC+C/bz5dHNOq5efK6+p59Y3f2JffiUfbc6mX3Qwd03qz8zUePx8Tm6H5JfX8O6Go7z341EKKmoJD/Tlw1+fy4CYEKesX0taaw4UHOeHA4UMiQtjTGKPblmu8DxyIo+b+nZ3Hn/6aDv5FTXcdl4SD140iEC/1sOzM0qr6vhsaw7B/j7EhAbQK8yfmNAAwgJ9UEpRZ7FypOg4e/Mq2Zdfwb78SjYcLCLA15tvf3f+KWHb3IMLt7B8Vx4/PXLhSUFvabBy21sZrN1fyJu3jKWkqo5XVh5gZ245sWEB3D4hiRvH9mVvXgVv/nCYpdtyqW/QTB4UzcyR8fz1850E+nnz8W/S6Rnib/dr0Jqy6np+2F/I6n0FrN5bSHZpNQDeXop/3TiSaSlxTlmu8AxtncgjAe7GymvqeWrpbt7/8SiJUUE8fc0IxiZ1vTW4P7+C29/K4HDRqSfd+Pt40SPYj4KKWiy27g2loG+PIAbGhPDr8/sz+qz2l71qbwFzFvzIq7NGMXVYU+A9tmQHb/5wmKeuSuHGsX0Bo5W7el8hr6zcz/qDxfj5eFFnsRLi78O1aQnMHp9IUs9gALZmlnL9/HUMig3jgzvGtbshyzhczPs/ZlJdb6HOYqXW9lNnsVLf0HqXlKVBs7+gkgarJsTfh3P7RzHx7GjGJPbgkY+3sTmzVEJc2EUC3IP9cKCQuR9uI7OkitvSk/j9JYPa7Mpoy8o9+dz73mb8fb148cZRxIYHkF9eQ15FLfnlNeRX1FJYWUtceAADY0IZEBPCgJiQTi3H0mBl3FMrSDurB6/+cjQA76w/wv98sp3bzkviz5cPbfV5m4+WsCgjiyFxoVw1KuHE4GDNfb3jGL96ZyMXDenFK7NG4+118pmwdRYr//xmL/9edYCwQF96hvjj5+2Fn4/x4+/jhZ+3F62fQKsYHBvKxLOjGdk34qTxbSprLcxZ8CNbJMSFHSTAPdzxWgtPfbmLd9YfZUBMCM9eN4LhCRGnfZ7WmgVrD/PkFzsZFBvGa3PSnDr2ymNLdvDehqP89D8Xsi2rjDlv/Miks6P5z+y0U0K3s95ce4jHPtvJrelJ/GV608Zgz7EKHli4hZ255dwwpg//c/nQVjcCXSUh3j6rVbM3v4JBvUI7PcSEp5CxUDxcsL8PT8xM4e1bx1JZY+HKl3/g2eV72+wWAKNVOvfDbfz1851cNLQXi+8a7/SBs2aOjKeuwcrLK/fzm3c3MiA6hOdvSLU7vAFuTk/i1vQkFqw9xBtrD2G1al77/iDT/7WG/Ioa/jM7jXlXD3doeAOE+Pvw1q1jSe0TwT3vb+bLbbkOnX9n1NQ3UHy87ow563X9wSKueGktU5/7nrve2Uh5Tb2rSzIVaYF7oLLqeh5fsoOPNmczLD6Muyb1x8er5bZcs2DNYX48XMx9UwZw/4Vn4+WAED0drTWTn1nJ4aIqooL9+OTudPr0CHLY/Busmt+8u5Gvd+YxrHc427LLuHBIL+ZdneK0LzgbNW+JPzxtMAmRnd0Ydub115RV15NZXE1mSRVZJdVkFleRX1ELQKCvNwmRgfTpEUQf221seEAr7wNjXm0ZFh9OQmTn/z+HCo8z78tdLNuRR1x4AJckx/Lf9UfoExnIK7NGMyQurNPzBGOkS6vW9IvuniOOmqupb6Csup5eYQEOn7d0oYhTfLX9GI98vI2iVq7VCcYXk3+/dgQzRvTu1rpeXXWAfy7fy3t3nHPaLz67orqugV+8tp69xyp4dHoy16YldNuue2WthZsX/EjGke45Y9bbSxEXHkCfyKATgR3s70NOqRHomSXVZBVXUdHFES29FExLieP285IY2ff0Y9OXVtXxwor9vL3uMP4+Xvz6/P7cdl4/Av28+elwMXe/u4nymnqemJnCNaMTOlRDTmk1n/+cw5KtOWzPLkcpuGfyAH57wUB8vLunk2HT0RIeXLiF7NJqfnfxIO6Y0M8he42NJMBFqyprLRxt5agSgJgwf6e3Slujtaay1nLKGZuOVGtpoKbOSniQ85bRFkuDlf0FlXTmo9eVj2logA9x4QEdCrGyqnpyy6uxttGj1tr2zdKg+XxbDu9tOEpFjYW0syK5fUI/Lhra60R4Ha+1sCu3nG3ZZWzLLmPFrnwqauq5fkwfHrjobGJCT26tFlTUct/7m1l3sIgbx/bl0elDT/kivL7ByrGyGlbuLeCzLTn8eLgYgOEJ4Uwf3ps9eRUs3pjFqL4RPH/DSIfuwbVUZ7Hywop9vLxyP3HhgQyODWXF7nzOSerBs9enOqzL0SkBrpSaCjwPeAOvaa3ntTe9BLgQ7qey1sKinzJZsPYQWSXVnBUVRGqfCHbklHOg2YaqZ4g/YxIjue+Cge12kVgarPxj+V5eWXmAYfFhjE2MIresmpyyGnJLqymorD0xzwExIcwY0ZvpI3qfOGwUjOGJH/loGwBPXpXilL3IfXkV3L9wCztyyrlmdAKPTje+/F68MYvHluzAy0vxxMxhXJEab/eyHB7gSilvYC9wEZAF/ATcqLXe2dZzJMCFcF+WBivLduTx+pqD5JTWkNw7jGHx4aTEh5OSEN7pvuHlO/P444c/U1PfQFx4AL0jAokLDyAu3LgdnhDBkLi2j1zJLK7itx9sZtPRUq4ZncDjM5Idch1Zq1WzYO0hnl62h1B/H/7vqhQuSY49aZojRcd5YOEWNh0tZWZqbx6/YhjhgV3f23NGgI8HHtNaX2L7+2EArfVTbT1HAlwI0RlWq0YpuvwdhaXB6OL413f7iQzya/Xi2Y0J2JiFutkDVq1p0JqGBtutFeosDZTXWE775belwcrLKw/w/Ip9xIYF8MYtYzi7V2iX1qOtALdncxQPZDb7Ows4p5UF3wncCdC3b187FieE8DT2Hvnk4+3FgxcPIn1AT97dcBRLG538qvEIn5Nv8FIKHy+Fl5fCW9luvWBMYg9mjOjd7obFx9uL+y4YyISBPfnnN/vo7YRDcJ0+mJXWej4wH4wWuLOXJ4QQLZ3TL4pz+kW5ZNkj+0by9q1jnTJve46xyQaaX+AxwXafEEKIbmBPgP8EDFRKJSml/IAbgCWOKUsIIcTpdLkLRWttUUrdAyzDOIxwgdZ6h8MqE0II0S67+sC11kuBpQ6qRQghRCfIYFZCCGFSEuBCCGFSEuBCCGFSEuBCCGFS3ToaoVKqADjSxaf3BAodWI5ZyHp7Fk9db/Dcde/Iep+ltY5ueWe3Brg9lFIZrY0F4O5kvT2Lp643eO6627Pe0oUihBAmJQEuhBAmZaYAn+/qAlxE1tuzeOp6g+eue5fX2zR94EIIIU5mpha4EEKIZiTAhRDCpEwR4EqpqUqpPUqp/Uqpua6ux1mUUguUUvlKqe3N7uuhlFqulNpnu410ZY3OoJTqo5T6Tim1Uym1Qyn1W9v9br3uSqkApdSPSqmttvV+3HZ/klJqg+39vtA2XLPbUUp5K6U2K6U+t/3t9uutlDqslNqmlNqilMqw3dfl9/kZH+C2iye/BEwDhgI3KqWGurYqp3kTmNrivrnACq31QGCF7W93YwF+p7UeCowD7rb9j9193WuBKVrrEUAqMFUpNQ74G/BPrfUAoAS4zXUlOtVvgV3N/vaU9Z6stU5tdux3l9/nZ3yAA2OB/Vrrg1rrOuAD4AoX1+QUWuvVQHGLu68A3rL9/hYwsztr6g5a61yt9Sbb7xUYH+p43HzdtaHS9qev7UcDU4DFtvvdbr0BlFIJwGXAa7a/FR6w3m3o8vvcDAHe2sWT411Uiyv00lrn2n4/BvRyZTHOppRKBEYCG/CAdbd1I2wB8oHlwAGgVGttsU3iru/354A/AI1XGY7CM9ZbA18rpTbaLvgOdrzPnX5RY+E4WmutlHLb4z6VUiHAh8D9Wuvy5lf8dtd111o3AKlKqQjgY2CwaytyPqXU5UC+1nqjUup8F5fT3c7TWmcrpWKA5Uqp3c0f7Oz73AwtcE+/eHKeUioOwHab7+J6nEIp5YsR3u9qrT+y3e0R6w6gtS4FvgPGAxFKqcbGlTu+39OBGUqpwxhdolOA53H/9UZrnW27zcfYYI/Fjve5GQLc0y+evASYY/t9DvCpC2txClv/5+vALq31s80ecut1V0pF21reKKUCgYsw+v+/A66xTeZ26621flhrnaC1TsT4PH+rtb4JN19vpVSwUiq08XfgYmA7drzPTXEmplLqUow+s8aLJz/p2oqcQyn1PnA+xvCSecCjwCfAIqAvxlC812mtW37RaWpKqfOA74FtNPWJ/gmjH9xt110pNRzjSytvjMbUIq31/yql+mG0THsAm4FZWuta11XqPLYulN9rrS939/W2rd/Htj99gPe01k8qpaLo4vvcFAEuhBDiVGboQhFCCNEKCXAhhDApCXAhhDApCXAhhDApCXAhhDApCXAhhDApCXAhhDCp/w+CzTsSrIpTTAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "ename": "KeyError",
     "evalue": "'accuracy'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_13116\\3688262185.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;31m# plot the accuracy\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'accuracy'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'train acc'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'val_accuracy'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'val acc'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlegend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'accuracy'"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot the loss\n",
    "plt.plot(r.history['loss'], label='train loss')\n",
    "plt.plot(r.history['val_loss'], label='val loss')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "plt.savefig('LossVal_loss')\n",
    "\n",
    "# plot the accuracy\n",
    "plt.plot(r.history['accuracy'], label='train acc')\n",
    "plt.plot(r.history['val_accuracy'], label='val acc')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "plt.savefig('AccVal_acc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save it as a h5 file\n",
    "\n",
    "\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "model.save('model_resnet50.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "y_pred = model.predict(test_set)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2.73187868e-02, 6.35943949e-01, 3.36737245e-01],\n",
       "       [5.32117963e-01, 4.06336963e-01, 6.15450703e-02],\n",
       "       [2.18244940e-01, 1.21792853e-01, 6.59962177e-01],\n",
       "       [7.13846564e-01, 6.96882829e-02, 2.16465190e-01],\n",
       "       [8.45080912e-02, 1.32538576e-03, 9.14166570e-01],\n",
       "       [1.12954237e-01, 8.64453554e-01, 2.25921888e-02],\n",
       "       [5.32363169e-02, 7.21089959e-01, 2.25673750e-01],\n",
       "       [2.26125740e-05, 8.14217638e-05, 9.99895930e-01],\n",
       "       [4.68579568e-02, 9.51322854e-01, 1.81910372e-03],\n",
       "       [2.18738019e-02, 1.25456427e-03, 9.76871669e-01],\n",
       "       [4.89251651e-02, 8.53239179e-01, 9.78356451e-02],\n",
       "       [3.28370333e-02, 2.36797822e-03, 9.64794993e-01],\n",
       "       [8.04440752e-02, 2.88622886e-01, 6.30933046e-01],\n",
       "       [3.90192628e-01, 2.33580455e-01, 3.76226962e-01],\n",
       "       [1.83415916e-02, 9.48268533e-01, 3.33898999e-02],\n",
       "       [2.41261408e-01, 4.27105606e-01, 3.31632912e-01],\n",
       "       [8.70700061e-01, 3.90547724e-03, 1.25394493e-01],\n",
       "       [6.43375870e-06, 4.48106090e-04, 9.99545395e-01],\n",
       "       [2.33309418e-02, 8.75707209e-01, 1.00961827e-01],\n",
       "       [1.68869123e-01, 2.18794703e-01, 6.12336218e-01],\n",
       "       [1.15046855e-02, 9.62082505e-01, 2.64127720e-02],\n",
       "       [1.60634935e-01, 9.96036083e-03, 8.29404652e-01],\n",
       "       [2.98359673e-02, 7.91092038e-01, 1.79071948e-01],\n",
       "       [9.43630576e-01, 5.38715646e-02, 2.49781809e-03],\n",
       "       [3.87979671e-02, 1.11808345e-01, 8.49393725e-01],\n",
       "       [6.32739335e-04, 9.90709186e-01, 8.65799095e-03],\n",
       "       [4.13829535e-02, 8.79822254e-01, 7.87948146e-02],\n",
       "       [1.21594861e-01, 5.69236353e-02, 8.21481526e-01],\n",
       "       [9.52745974e-01, 2.06574630e-02, 2.65965573e-02],\n",
       "       [9.95284989e-02, 5.68932652e-01, 3.31538826e-01],\n",
       "       [3.69348004e-02, 4.25086558e-01, 5.37978649e-01],\n",
       "       [6.96831420e-02, 5.82942273e-03, 9.24487352e-01],\n",
       "       [9.27041247e-02, 2.95088857e-01, 6.12207055e-01],\n",
       "       [6.71517432e-01, 1.26601681e-01, 2.01880947e-01],\n",
       "       [1.10414894e-02, 8.96534026e-01, 9.24245268e-02],\n",
       "       [4.14094180e-02, 2.53581256e-01, 7.05009341e-01],\n",
       "       [5.02322521e-03, 9.86167133e-01, 8.80967174e-03],\n",
       "       [1.02342203e-01, 1.82328047e-04, 8.97475481e-01],\n",
       "       [3.22725862e-01, 4.01354134e-01, 2.75920063e-01],\n",
       "       [9.67599332e-01, 1.08619370e-02, 2.15387065e-02],\n",
       "       [2.16640588e-02, 3.52164507e-01, 6.26171410e-01],\n",
       "       [3.57131124e-01, 4.38901097e-01, 2.03967765e-01],\n",
       "       [6.37840211e-01, 3.41039225e-02, 3.28055769e-01],\n",
       "       [6.02720715e-02, 7.00991988e-01, 2.38735929e-01],\n",
       "       [4.69329627e-03, 9.39610958e-01, 5.56956455e-02],\n",
       "       [2.43041408e-03, 6.82524204e-01, 3.15045387e-01],\n",
       "       [4.87683788e-02, 4.26231205e-01, 5.25000334e-01],\n",
       "       [9.68200490e-02, 5.10944575e-02, 8.52085531e-01],\n",
       "       [8.17427486e-02, 2.78275937e-01, 6.39981270e-01],\n",
       "       [5.72731299e-03, 1.34207653e-02, 9.80851948e-01],\n",
       "       [9.86407876e-01, 4.04018769e-03, 9.55183804e-03],\n",
       "       [5.57873435e-02, 1.78392574e-01, 7.65820086e-01],\n",
       "       [1.04311565e-02, 3.71323347e-01, 6.18245482e-01],\n",
       "       [1.09694548e-01, 2.29822338e-01, 6.60483122e-01],\n",
       "       [5.56478053e-02, 1.09311447e-01, 8.35040748e-01],\n",
       "       [8.33302021e-01, 1.05132543e-01, 6.15654588e-02],\n",
       "       [3.20118934e-01, 2.38704294e-01, 4.41176802e-01],\n",
       "       [1.08633913e-01, 6.76979959e-01, 2.14386165e-01]], dtype=float32)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "y_pred = np.argmax(y_pred, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 2, 0, 2, 1, 1, 2, 1, 2, 1, 2, 2, 0, 1, 1, 0, 2, 1, 2, 1, 2,\n",
       "       1, 0, 2, 1, 1, 2, 0, 1, 2, 2, 2, 0, 1, 2, 1, 2, 1, 0, 2, 1, 0, 1,\n",
       "       1, 1, 2, 2, 2, 2, 0, 2, 2, 2, 2, 0, 2, 1], dtype=int64)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.preprocessing import image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=load_model('model_resnet50.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[ 6.7060997e+01,  5.4221001e+01,  4.7320000e+01],\n",
       "         [ 6.9060997e+01,  5.6221001e+01,  4.9320000e+01],\n",
       "         [ 7.3060997e+01,  6.0221001e+01,  5.3320000e+01],\n",
       "         ...,\n",
       "         [ 7.4060997e+01,  5.6221001e+01,  4.6320000e+01],\n",
       "         [ 5.5060997e+01,  3.7221001e+01,  2.7320000e+01],\n",
       "         [ 4.1060997e+01,  2.3221001e+01,  1.3320000e+01]],\n",
       "\n",
       "        [[ 7.5060997e+01,  6.2221001e+01,  5.5320000e+01],\n",
       "         [ 7.8060997e+01,  6.5221001e+01,  5.8320000e+01],\n",
       "         [ 8.1060997e+01,  6.8221001e+01,  6.1320000e+01],\n",
       "         ...,\n",
       "         [ 9.7060997e+01,  7.9221001e+01,  6.9320000e+01],\n",
       "         [ 7.3060997e+01,  5.5221001e+01,  4.5320000e+01],\n",
       "         [ 4.9060997e+01,  3.1221001e+01,  2.1320000e+01]],\n",
       "\n",
       "        [[ 8.7060997e+01,  7.4221001e+01,  6.7320000e+01],\n",
       "         [ 9.0060997e+01,  7.7221001e+01,  7.0320000e+01],\n",
       "         [ 9.3060997e+01,  8.0221001e+01,  7.3320000e+01],\n",
       "         ...,\n",
       "         [ 1.0106100e+02,  8.3221001e+01,  7.3320000e+01],\n",
       "         [ 7.5060997e+01,  5.7221001e+01,  4.7320000e+01],\n",
       "         [ 5.0060997e+01,  3.2221001e+01,  2.2320000e+01]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[ 1.0406100e+02,  8.9221001e+01,  9.4320000e+01],\n",
       "         [ 1.0206100e+02,  8.7221001e+01,  9.2320000e+01],\n",
       "         [ 9.9060997e+01,  8.4221001e+01,  8.9320000e+01],\n",
       "         ...,\n",
       "         [-1.0939003e+01, -1.6778999e+01, -1.4680000e+01],\n",
       "         [-1.0939003e+01, -1.6778999e+01, -1.4680000e+01],\n",
       "         [-1.0939003e+01, -1.6778999e+01, -1.4680000e+01]],\n",
       "\n",
       "        [[ 1.0606100e+02,  9.1221001e+01,  9.6320000e+01],\n",
       "         [ 1.0406100e+02,  8.9221001e+01,  9.4320000e+01],\n",
       "         [ 1.0006100e+02,  8.5221001e+01,  9.0320000e+01],\n",
       "         ...,\n",
       "         [-5.9390030e+00, -1.1778999e+01, -9.6800003e+00],\n",
       "         [-5.9390030e+00, -1.1778999e+01, -9.6800003e+00],\n",
       "         [-5.9390030e+00, -1.1778999e+01, -9.6800003e+00]],\n",
       "\n",
       "        [[ 1.0806100e+02,  9.4221001e+01,  9.6320000e+01],\n",
       "         [ 1.0606100e+02,  9.2221001e+01,  9.4320000e+01],\n",
       "         [ 1.0206100e+02,  8.8221001e+01,  9.0320000e+01],\n",
       "         ...,\n",
       "         [ 6.0997009e-02, -5.7789993e+00, -3.6800003e+00],\n",
       "         [ 6.0997009e-02, -5.7789993e+00, -3.6800003e+00],\n",
       "         [ 6.0997009e-02, -5.7789993e+00, -3.6800003e+00]]]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "img=image.load_img('Datasets/Test/lamborghini/11.jpg',target_size=(224,224))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[252., 252., 252.],\n",
       "        [252., 252., 252.],\n",
       "        [252., 252., 252.],\n",
       "        ...,\n",
       "        [194., 188., 174.],\n",
       "        [215., 209., 197.],\n",
       "        [241., 235., 223.]],\n",
       "\n",
       "       [[252., 252., 252.],\n",
       "        [252., 252., 252.],\n",
       "        [252., 252., 252.],\n",
       "        ...,\n",
       "        [247., 245., 233.],\n",
       "        [245., 242., 233.],\n",
       "        [244., 241., 232.]],\n",
       "\n",
       "       [[252., 252., 252.],\n",
       "        [252., 252., 252.],\n",
       "        [252., 252., 252.],\n",
       "        ...,\n",
       "        [245., 248., 241.],\n",
       "        [244., 250., 248.],\n",
       "        [244., 250., 248.]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[190., 206., 229.],\n",
       "        [190., 206., 229.],\n",
       "        [190., 206., 229.],\n",
       "        ...,\n",
       "        [172., 179., 187.],\n",
       "        [171., 180., 187.],\n",
       "        [171., 180., 187.]],\n",
       "\n",
       "       [[187., 205., 227.],\n",
       "        [187., 205., 227.],\n",
       "        [187., 205., 227.],\n",
       "        ...,\n",
       "        [172., 179., 187.],\n",
       "        [171., 180., 187.],\n",
       "        [171., 180., 187.]],\n",
       "\n",
       "       [[185., 206., 227.],\n",
       "        [185., 206., 227.],\n",
       "        [187., 205., 227.],\n",
       "        ...,\n",
       "        [172., 179., 187.],\n",
       "        [171., 180., 187.],\n",
       "        [171., 180., 187.]]], dtype=float32)"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x=image.img_to_array(img)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(224, 224, 3)"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=x/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 224, 224, 3)"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x=np.expand_dims(x,axis=0)\n",
    "img_data=preprocess_input(x)\n",
    "img_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.02122196, 0.49325418, 0.4855238 ]], dtype=float32)"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(img_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "a=np.argmax(model.predict(img_data), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ True])"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a==1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
